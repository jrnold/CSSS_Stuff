Interpreting Product-Variable Models of Interaction Effects*

Lowell Hargens
University of Washington, Seattle

Working Paper no. 67
Center for Statistics and the Social Sciences
University of Washington
November 8, 2006

* This paper has benefited from valuable advice and encouragement given by Paul
Allison, Herbert Costner, Christine Fountain, Jerry Herting, Beth Hirsh, Stephanie
Liddle, Stanley Lieberson, J. Scott Long, Barbara Reskin, Stewart Tolnay and Michael
Ward. Direct correspondence to Lowell Hargens, Department of Sociology, University
of Washington, Seattle, WA 98195-3340. Email: hargens@u.washington.edu.

2

Abstract

Among those who use multiple regression analysis or its offshoots, the dominant method
of modeling an interaction effect of two independent variables on a dependent variable is
to include a product variable in a linear estimation equation. Textbook writers and
researchers almost always interpret the coefficient for the product variable as describing
both how the first independent variable influences the effect of the second independent
variable, and vice versa. As a result, writers often claim that interaction effects are
“symmetrical.” In this paper I distinguish between the regression surface produced by
estimating a product-variable model of an interaction effect, and the causal mechanisms
that produce the regression surface. I discuss four types of interaction effects, and show
that the meaning of the product variable’s coefficient differs across types. I also show
that one should use the same estimation equation for different types of interaction effects.
These considerations imply that the usual interpretation of the product variable’s
coefficient is almost always wrong, and that researchers need strong theory or knowledge
before they can interpret the results of a product variable model as giving information
about the causal mechanisms that constitute an interaction effect.

3

Interpreting Product-Variable Models of Interaction Effects1

Many interesting findings in the social sciences involve “interaction” or
“moderator” effects (Cohen et al. 2003, p. 255; Corno et al. 2002). Two independent
variables have an interaction effect on a dependent variable if the relationship of an
independent variable with the dependent variable changes across values of the other
independent variable.2 For example, in an early study of radio listenership, Lazersfeld
found that age was positively related to listening to classical music programs among the
highly educated, but negatively related to it among the less educated (Zeisel 1968, pp.
123-25). Although there are many ways to model interaction effects (Stolzenberg 1974,
Allison 1977, Southwood 1978, Fisher 1988), quantitative studies using multiple
regression analysis or its offshoots almost always employ product variables to represent
them. Indeed, most textbooks treat only that option.
The product-variable approach to modeling an interaction effect involves
computing the product of the independent variables involved in the interaction and
including the new product variable in an equation that typically also contains each of the
independent variables that form the product (Saunders 1956, Blalock 1965). For
example, given a dependent variable Y and independent variables X and Z, we would
calculate a variable that is the product of X and Z and include this new variable as well as
X and Z individually in a regression equation, as shown in equation 1.
Y = β 0 + β x X + β z Z + β xz ( XZ ) + u

(1)

4
Higher order interaction effects—those involving three or more independent variables—
can also be modeled by forming products of the constituent independent variables (see
Blalock 1965, Cohen et al. 2003, pp. 290-91)
Omitting the product variable from equation 1 forces the regression surface to be
a two dimensional plane, which specifies that X and Z have only additive effects on Y
(Cohen et al. 2003, pp. 257-259). In contrast, including the product variable in equation
1 allows the best fitting regression surface to be “warped” rather than forcing it to be two
dimensional (see Figure 1).
[ Figure 1 about here ]
Including the XZ product term in equation 1 complicates the interpretation of the
resulting regression coefficients. Although there are many good discussions of the
meanings of βx and βz in equation 1 (e.g., Allison 1977, Marsden 1981, Braumoeller
2004), treatments of the meaning of the coefficient for the product term (βxz) are rare and,
to my knowledge, they are almost always wrong.
In this paper I show that researchers must specify the kind of interaction effect
they are modeling before they can specify what the value of βxz tells us about the causal
mechanisms that underlie the interaction effect. Because this is rarely done,
misinterpretations of interaction effects are frequent.

Describing vs. Interpreting Regression Surfaces Generated by Interaction Effects
Interpretational errors associated with modeling interaction effects using product
variables stem from a failure to distinguish between (a) the regression surface produced
by estimating a product-variable model and (b) the causal mechanisms that generated that

5
regression surface. One can concisely describe the shape of the regression surface
produced by estimating equation 1 by taking the partial derivatives for X and Z in that
equation (Stolzenberg 1979, p. 472). Doing this shows that the slope of the regression
surface in the X dimension is a linear function of Z, and that the slope of the regression
surface in the Z dimension is a linear function of X (this kind of interaction effect is
therefore often called a “linear by linear interaction”).3

∂Y
= β x + β xz Z
∂X

(2)

∂Y
= β z + β xz X
∂Z

(3)

Equation 2 tells us that the slope of the regression surface in the X dimension
equals β x when Z equals zero and that it changes by β xz for each unit of increase in Z’s
value. Equation 3 specifies that the slope of the regression surface in the Z dimension
equals β z when X equals zero and that it changes by β xz for each unit of increase in X’s
value. For example, X’s slope in Figure 1 is positive when Z = 0, which means that β x is
positive. As Z increases, however, the slope of the regression plane in the X dimension
becomes less positive (implying that β xz has a negative sign) and when Z = a, X’s slope,
which at that point equals βx + (βxz, × a), is decidedly negative. The same pattern holds
for the slope of the regression plane in the Z dimension; it is positive when X = 0 but as
X increases it becomes less positive and is negative when X = b.
Sometimes a description of the regression surface produced by estimating a
product-term interaction model is all that one wants. For example, if the one has
nonexperimental data and the regression model is correctly specified, or if the data come

6
from a randomized experiment, equation 2 gives an estimate of the causal effect of a unit
change in X on Y’s value, and equation 3 gives an estimate of the causal effect of a unit
change in Z on Y’s value.
Very often, however, researchers want to go beyond estimating causal effects to
specify the causal mechanisms that produce those effects (Marini and Singer 1988). The
distinction between causal effects and causal mechanisms (Holland 1988, Smith 1990)
involves the difference between describing what happens when the value of an
independent variable changes (causal effect) and how or why it happens (causal
mechanisms). For interaction effects, describing the causal mechanism that generates an
interaction involves specifying both if each independent variable affects the dependent
variable and whether each independent variable affects the other independent variable’s
causal impact on the dependent variable.
Many authors treat equations 2 and 3 as specifying the causal mechanism that
constitutes an interaction effect. Doing so leads to a peculiar prospect, however.
Examining those equations, one finds that β xz apparently specifies both Z’s effect on the
X-Y causal relationship and X’s effect on the Z-Y causal relationship. This feature has
led many authors to characterize the product-variable approach as “symmetrical” (Aiken
and West 1991, p. 10; Cohen et al. 2003, pp. 266, 271; Fox 1997, p. 146) or, put
differently, that Z’s effect on X’s causal impact on Y, and X’s effect on Z’s causal impact
on Y are “two sides of the same coin” (McClendon 1994, p. 274), or that X and Z
contribute equally to their mutual interaction (Fisher 1988, p. 88). If these claims were
true (fortunately they are not), the product-variable approach would be appropriate only

7
for situations in which researchers have good reasons to believe that Z’s causal effect on
X’s causal impact on Y is the same as X’s effect on Z’s causal impact.
This paper shows that interpreting equations 2 and 3 as specifying the causal
mechanism underlying an interaction effect is incorrect. It is incorrect because equation
1 can estimate the coefficients for several different types of interaction effects.
Researchers therefore must have additional knowledge before they can interpret the
coefficients produced by estimating equation 1 as giving information about the causal
mechanism that underlies an interaction effect.

From Interaction Effects to Regression Surfaces

Type I Interaction Effects (Two Effects Conditioned on Zero, Two Moderator Effects)
To understand of the meaning of the coefficient for the product variable in a
product-variable interaction model, one can begin by specifying a generic interaction
effect and then derive the regression equation that a researcher would use to estimate the
components of that interaction. Accordingly, let us consider an interaction effect
involving two independent variables, X and Z, and a dependent variable, Y, in which
each independent variable affects the dependent variable in the other independent
variable’s absence,4 and in which each independent variable affects the other independent
variable’s effect on Y. This kind of interaction effect, which I will refer to as a Type I
interaction effect, is illustrated graphically by Figure 2. Figure 2 portrays (a) an
independent variable’s effect on a dependent variable when the other independent
variable equals zero as a directed line pointing from the independent (X or Z) to the
dependent variable (Y), and (b) an independent variable’s impact on another independent

8
variable’s effect on a dependent variable as a directed line pointing to the line that
connects the second independent variable to the dependent variable. For labeling
purposes, let us call the first kind of effect an “effect conditioned on zero” and the second
kind of effect a “moderator effect.” Then a Type I interaction effect consists of two
“effects conditioned on zero” and two “moderator effects.” Note that in this kind of
interaction the magnitude of Z’s effect on the X’s impact on Y need not be equal to X’s
effect on the Z’s impact on Y; this type specifies only that both of these effects are
present.
[ Figure 2 about here ]
We can translate the above specifications into equations by following some of the
conventions of the multilevel-modeling literature (Hox 2002, see also Fisher 1988, and
Allison 1999, pp. 166-69). Equation 4 is an overall equation specifying that both X and
Z affect Y, while equation 5 specifies that X’s effect on Y is a linear function of Z that
equals α 0 when Z equals zero and equation 6 specifies that Z’s effect on Y is a linear
function of X that equals γ 0 when X equals zero. Borrowing the terminology of the
multilevel-modeling literature, I refer to equation 4 as a “level 1” equation and equations
5 and 6 as “level 2” equations.5 These three equations jointly specify a Type I interaction
effect.
Y = β0 + β x X + βz Z + u

(4)

β x = α 0 + α1Z

(5)

βz = γ 0 + γ1X

(6)

Substituting equations 5 and 6 into equation 4 produces equation 7, which can be
rewritten as equation 8. Because equation 8 is structurally identical to equation 1, one

9
would use equation 1 to estimate the various components of the interaction effect
specified in equations 4 through 6.
Y = β 0 + (α 0 + α1Z ) X + (γ 0 + γ 1 X ) Z + u

(7)

Y = β 0 + α 0 X + γ 0 Z + (α1 + γ 1 ) ZX + u

(8)

Equation 8 shows that for a Type I interaction effect, the product term’s
coefficient (βxz in equation 1) equals the sum of Z’s impact on X’s effect on Y (α1) and
X’s impact on Z’s effect on Y (γ1). Without additional information about α1 or γ 1 one
cannot determine either coefficient’s value from the value of βxz. This means that when
we use equation 1 to estimate a Type I interaction effect and reject the null hypothesis
that the coefficient for the product term equals zero, we can infer only that some kind of
interaction effect is present but cannot specify anything concrete about the components of
the causal mechanism underlying the interaction effect.
Equation 8 also shows why it is wrong to claim that βxz in equation 1
simultaneously describes both X’s impact on Z’s effect on Y and Z’s impact on X’s
effect on Y. Although we obtain only one coefficient for the product term when we
estimate equation 8, that does not mean that the two underlying causal coefficients ( α1
and γ 1 ) are equal, it means only that we cannot determine their individual magnitudes
without further information or assumptions that will help us solve this kind of
identification problem (Manski 1993, pp. 32-36). Indeed, even in the unlikely case where

α1 equals γ1, the coefficient for the product term will not equal their common value;
instead it will be twice that value.

10
One interesting possibility that equation 8 encompasses is that where α1 and γ 1
are equal in magnitude but have opposite signs. In these cases one is likely to obtain an
estimate of βxz that is close to zero, which would lead most researchers to conclude that X
and Z have only additive effects on Y when in fact they have an interaction effect. If one
is confident that α1 and γ 1 have the same sign it is reasonable to argue that a zero value
for βxz implies that the effects of X and Z are additive. Inferring additivity from a zero
value of βxz without knowing that the components of the interaction have the same sign,
however, commits the fallacy of affirming the consequent. Specifically, just as it is
fallacious to accept a null hypothesis, it is fallacious to decide that no interaction effect
exists on the basis of (1) the fact that when no interaction is present the coefficient for a
product term will equal zero and (2) the observation of a zero-value for that coefficient.
I noted above that one must have some kind of additional information about α1 or

γ 1 before one can determine a value for either of these coefficients in a Type I interaction
effect. If one knew α1 ’s value, for example, one could subtract it from βxz to obtain an
estimate of γ 1 . Similarly, if one knew that that α1 was a specific multiple of γ 1 and had
an estimate of βxz , it would be possible to use knowledge of the multiple (k) and the
results of two simultaneous equations ( α1 = k γ 1 and α1 + γ 1 = βxz ) to estimate α1 and

γ 1 . A third strategy is available to researchers who know that X’s impact on Z’s effect
on Y has a different functional form than Z’s impact on X’s effect on Y. If one knew that

β 2 = γ 0 + γ 1 X , for example, one would substitute this equation and the other level-2
equation 5 into level-1 equation 4 to obtain Y = β 0 + α 0 X + γ 0 Z + α1ZX + γ 1Z X + u .

11
This equation contains two different product variables that allow one to obtain separate
estimates for α1 and γ 1 . Unfortunately, because the product variables ZX and Z X will
be highly correlated, this strategy produces imprecise estimates of α1 and γ 1 .
In general, strategies such as those outlined above for obtaining unique estimates
of α1 and γ 1 require knowledge or theoretical precision that we rarely, if ever, possess.
Without them an estimate of βxz’s value can tell us nothing about either X’s impact on Z’s
effect on Y or Z’s impact on X’s effect on Y.

Type II Interaction Effects (Two Effects Conditioned on Zero, One Moderator Effect)
A popular approach to dealing with the identification problem noted above is to
assume either that X has no impact on Z’s effect on Y, or that Z has no impact on X’s
effect on Y. Below I will refer to this as a Type II interaction effect.6 If we specify that

γ 1 in equation 6 equals zero, for example, level-2 equation 6 becomes β z = γ 0 , and the
estimation equation is Y = β 0 + α 0 X + γ 0 Z + α1ZX + u . Figure 3 shows this kind of
interaction effect.
[ Figure 3 about here ]
As is true for Type I interaction effects, one would use equation 1 to estimate the
coefficients specified by this new equation. Now, however, βxz in equation 1 corresponds
to α1 ’s value. Of course, a parallel argument that α1 in equation 5 instead of γ 1 equals
zero produces the equation Y = β 0 + α 0 X + γ 0 Z + γ 1ZX + u . In this case βxz in equation 1
corresponds to γ 1 ’s value. Thus, it is clear that the meaning of the coefficient for the

12
product variable in equation 1 depends on the nature of the interaction effect that a
researcher believes is generating the regression surface given by equation 1.
Researchers who specify a causal mechanism underlying an interaction effect are
more likely to specify a Type II interaction effect than any of the other types this paper
discusses, and the vast majority of Type II specifications occur in the multilevel analysis
literature. In contextual-effect models, for example, researchers specify that contextual
variables affect the effects of individual-level variables but not vice versa. For example,
let us consider a simple model involving the effects of an individual level variable, pupil
SES, and a contextual variable, schools’ per pupil funding, on individual pupils’
achievement-test scores. Researchers would typically specify a contextual effect model
for these variables with level-1 equation 9 stipulating that individuals’ test scores (Y) are
a function of individuals’ SES levels (X), and two level-2 equations (10 and 11)
stipulating that both the intercept and slope of the level-1 equation are functions of
schools’ per pupil funding (Z).7
Y = β0 + β x X + u

(9)

β 0 = α 0 + α1Z + e0

(10)

β x = γ 0 + γ 1Z + e1

(11)

Substituting equations 10 and 11 into equation 9 and simplifying, we obtain
equation 12 which is equivalent to equation 1 except for its more complicated error term.
Y = α 0 + α1Z + γ 0 X + (γ 1 ) XZ + [e0 + e1 X + u ]

(12)

Equation 12 specifies that the coefficient for the product term estimates the
contextual effect of schools’ per pupil funding levels on the individual-level effect of
pupils’ SES on test scores. It is important to keep in mind, however, that equations 9

13
through 12 do not in themselves justify this specification, they only make explicit the
knowledge that a researcher should possess before constructing those equations.
Multilevel modeling textbooks show how to use versions of equations 9 through 12 to
obtain estimates of contextual effects, but rarely if ever discuss the prior problem of
theoretically justifying the assumption that contextual variables cause variation in the
effects of individual-level variables, but that individual-level variables do not cause
variation in the effects of contextual variables.
The textbooks’ silence on the possibility of individual-level variables affecting the
effects of contextual variables does not justify the assumption that they do not do so.
Algebraically, one could just as easily place Z in the level-1 equation and X in the level-2
equations to produce an “individual effects” model asserting that variation in the effect of
schools’ per pupil funding on test scores stems from variation in pupil SES,8 and
substantive questions exist for which this alternative kind of specification is appropriate
(Kozlowski and Klein 2000). Indeed, it is probably often reasonable to admit that
“contextual effects” and “individual effects” coexist, in which case we are back to the
Type I interaction effect model discussed above (although one with a more complicated
error term than equation 1 contains) in which it is impossible to determine the meaning of
the coefficient for the product term. In general, it is difficult to avoid the conclusion that
the popularity of the assumption that individual-level variables do not affect the effects of
contextual-level variables rests on unconsidered convention rather than on conscious
deliberation.

14

Type III Interaction Effects (One Effect Conditioned on Zero, One Moderator Effect)
One class of interaction effect models in which it is relatively easy to specify the
causal mechanisms underlying an interaction effect consists of cases in which an
independent variable (X) affects a dependent variable and a second independent variable
(Z) affects cases’ exposure to one or more values of X. As an example, consider the
effect of whether a mother smokes tobacco on the likelihood that a preschool child
exhibits asthma symptoms. One would expect that the difference in asthma symptoms
between children whose mothers who smoke tobacco and those whose mothers do not
will be smaller for children with mothers who are employed outside the home, because
differences in preschoolers’ exposure to tobacco smoke will be smaller among this group
than among those whose mothers work in the home. However, whether a mother works
outside the home has no effect on the likelihood that a preschooler will develop asthma
among preschoolers whose mothers who do not smoke tobacco.
[ Figure 4 about here ]
Figure 4 presents a diagram representing this kind of interaction effect. Note that
the omission of an arrow from Z to Y in this figure represents the fact that Z is causally
related to Y only through its effect on X’s effect on Y. This kind of interaction effect
nicely illustrates the distinction between a causal effect and a causal mechanism. If a
mother who smokes were to quit working outside the home, one can expect that her
preschool child would be more likely to develop asthma than if she were to keep that job.
The causal mechanism that produces this causal effect does not involve a direct causal
link between working outside the home and asthma, however, it is produced entirely by
the effect of working outside the home on the effect of having a mother who smokes.

15
We can turn the above theoretical specifications into level-1 equation 13 and
level-2 equation 14, where X is a binary variable indicating whether a mother smokes, Z
is a binary variable indicating whether the mother works outside the home, and Y is a
measure of the extent to which a preschooler has developed asthma. Substituting
equation 14 into equation 13, we obtain equation 15.

Y = β0 + β x X + u

(13)

β x = α 0 + α1Z

(14)

Y = β 0 + α 0 X + α1ZX + u

(15)

This equation differs structurally from equation 1 because it does not include a
“first order” or “additive effect” term for Z. Using equation 1 rather than 15 will produce
consistent, but inefficient estimates of the coefficients for this interaction because the
equation contains an irrelevant variable (Allison 1977). Thus, if we believed that
equations 13 and 14 specify the causal mechanisms underlying an interaction effect, we
would not use equation 1 to estimate its parameters. This conclusion is at odds with the
claim that researchers should always include lower-order terms when estimating
interaction-effect models (McClendon 1994, pp. 286-287; Fox 1997, pp. 148-149; Cohen
et al. 2003, p. 284). Whether lower-order terms need to be included in an estimation
equation depends partly on the kind of interaction effect that one believes to be present
(see also Bobko 1986, Cronbach 1987).
One’s theoretical specification of the causal mechanisms underlying an
interaction effect is not the only determinant of the estimation equation one should use,

16
however, because the types of scales that are used to measure the variables involved in
the interaction also play a role. Specifically, when one or more of these variables are
measured in terms of an interval scale,9 it may be necessary to include a first-order term
in one’s estimation equation even though the theoretical equations for the interaction
effect suggest that it should be omitted (Allison 1977, p. 150). This is because interval
scales have an arbitrary zero point, which in turn requires that one use an estimation
equation that allows for possible changes in that zero point. A general rule for Type III
interaction effect models is that whenever the variable specified in the level-1 equation
(X) is measured in terms of an interval scale, we need to use an estimation equation that
includes a first-order term for the moderating variable (Z).
To see this, let us consider a Type III interaction in which both X and Z are
quantitative variables. Suppose that X in equation 13 is measured in terms of an interval
scale. Since the score of zero for such a scale is arbitrary, we may add any non-zero
constant to the existing values of X without altering any of the essential properties of X.
Specifying the constant as c, we might create a new variable, x, where x = X + c,
implying that X = x – c (Allison 1977). Substituting this into equation 13 we have for our
new level-1 equation Y = β 0 + β x ( x − c ) + u and once again equation 14 is the level-2
equation. Substituting equation 14 into the new level-1 equation yields equation 16,
which can be simplified to equation 17, in which β 0* = β 0 + α 0c and β z* = −α1c .

Y = β 0 + α 0c + α 0 x − α1cZ + α1 xZ + u

(16)

Y = β 0* + α 0 x + β z*Z + α1 xZ + u

(17)

17
Equation 16 is structurally identical to equation 1 and includes Z as a regressor
even though the theoretical equations specify that Z is does not causally affect Y when X
equals zero. We can justify omitting Z from the estimation equation only if there is
reason to believe that α1 or c, which compose β z* , equals zero. We have already
specified that c is non-zero, however, and if we believed that α1 equals zero we would
not be estimating an interaction-effect model in the first place.
Both β 0* and β1* in equation 17 are affected by one’s choice of a value for c. This
makes sense because the former is the regression plane’s intersection with the Y axis
when all of the independent variables, including X, equal zero, and the latter is the slope
of the regression plane in the Z dimension when X equals zero. Returning to Figure 1,
for example, if we changed the X’s zero point to be at point b on the X axis, β 0* ’s value
would increase and β1* ’s value would be negative rather than positive. In contrast,
Equation 17 shows that changes in X’s zero point will not affect the coefficient for X
itself or the coefficient for the product variable.
Let us next consider the case where it is the level-2 variable (Z) that is measured
in terms of an interval scale rather than the level-1 variable. Equation 13 will be the
level-1 equation, but following the same logic as above, the level-2 equation will now be

β1 = α 0 + α1 ( z − c ) . Substituting this into equation 12 and simplifying, we obtain
equation 18.
Y = β 0 + (α 0 + α1c ) X + α1 Xz + u
= β 0 + β1* X + α1 Xz + u

(18)

18
In this case there is no additive coefficient for z in the estimation equation, and the
only coefficient affected by the choice of zero value for Z is β1* . Because β1* tells us the
slope of the regression surface in the X dimension when Z equals zero, it should be
affected by our arbitrary choice of Z’s zero value.
In sum, when using a product variable to model a Type III interaction effect we
must consider not only the level-1 and level-2 equations to determine an appropriate
equation for estimation and testing, but also whether any of the variables in the level-1
equation are measured in terms of interval scales. If they are, the estimation equation
will have to include additive effects that the level-1 and level-2 equations do not imply.

Type IV Interaction Effects (No Effects Conditioned on Zero, Joint Moderation)
A final type of interaction effect comprises instances where only the simultaneous
occurrence of certain values of two or more independent variables produces a given value
or values on a dependent variable. Almost all substantive instances of these interactions
involve binary independent variables.10 For example, whether a person embezzles money
from a business depends on whether the person simultaneously has a propensity to
embezzle and the opportunity to do so; when the opportunity to embezzle is absent
variation in the propensity to embezzle has no effect on embezzling, and when the
propensity to embezzle is absent, variation in the opportunity to embezzle has no effect
on embezzling. Bobko (1986) gives further examples of this kind of interaction effect.
Figure 5 presents a graphical representation of a Type IV interaction effect for
two independent variables, X and Z. To indicate that only the joint occurrence of certain
values of both independent variables affects the dependent variable, Figure 5 represents

19
their joint occurrence by using the multiplication operator and grouping both variables
within a circle. Returning to the embezzlement example, one could construct binary
variables for having the propensity to embezzle (X = 0 if no, X = 1 if yes) and having
opportunity to do so (Z = 0 if no, Z = 1 if yes). The product X*Z will then equal one
when both X and Z have values of one but zero if either or both equal zero. X and Z
appear in the level-1 equation for a Type IV interaction effect only as parts of the product
term (see equation 19), reflecting the specification that variation in X has no effect on the
dependent variable when Z equals zero and that variation in Z has no effect on the
dependent variable when X equals zero. Note also that this kind of interaction involves
no level-2 equations

Y = β 0 + β1 XZ + u

(19)

As noted earlier, many have claimed that the coefficient for the product term in
product-term models of interaction effects simultaneously describes each independent
variable’s effect on the other’s effect on the dependent variable. This claim is true for
Type IV interactions, but false for the other types. In the embezzlement example, β1 in
equation 19 describes both how variation in the propensity to embezzle affects the effect
of having the opportunity to embezzle (the latter equals zero when one does not have the
propensity, and β1 when one does), and how variation in having the opportunity to
embezzle affects the effect of having the propensity to embezzle (the latter equals zero
when one does not have the opportunity and β1 when one does).
Equation 19 is both the theoretical equation for a Type IV interaction effect and,
in most cases, the equation one would use to estimate the coefficients describing a Type
IV interaction. As is true for Type III interactions, however, if one of the independent

20
variables in equation 19 is measured in terms of an interval scale, an additive effect for
the other will need to be added to equation 19 to take account of the arbitrariness of the
zero point of the interval-scale independent variable. In fact, when both independent
variables are measured in terms of interval scales, Allison (1977, p. 150) showed that
equation 1 is the appropriate estimation equation but also that special estimation
procedures are needed because in this case Type IV interactions imply constraints on the
coefficients being estimated.

Conclusion
The main lesson of this paper is that researchers who want to interpret the results
of a product-variable interaction effect model in terms of the causal mechanisms that
underlie the interaction effect need at a minimum to specify what type of interaction
effect is at work. In addition, if it is a Type I interaction effect, researchers also need
knowledge that allows them to disentangle the components that make up the coefficient
for the product variable. These tasks require preexisting substantive or logical
information about the interaction effect. Without such information, we cannot go beyond
describing the regression surface that we obtain when we model it with a product
variable.
The distinction between describing regression surfaces and identifying causal
mechanisms holds for all causal analyses, not just models with interaction effects (Bollen,
pp. 68-71; Fox, pp. 126-128). In additive models, however, the connection between a
theoretical model and the partial derivatives that characterize the regression surface is
clear and direct because the variables we include in our estimation equations are the same
as those that our theory specifies to be causes of a dependent variable. In contrast, when

21
we model interaction effects we include product variables that typically do not directly
correspond to the causal mechanisms at work and that are compatible with several
different causal mechanisms. We have seen, for example, that equation 1 should be used
to estimate the parameters of a Type I interaction, a Type II interaction, or a Type III
interaction in which a variable appearing in the level-1 equation is measured in terms of
an interval scale. Obviously, estimates of the coefficients in equation 1 tell us nothing
about the kind of interaction effect that produced the regression surface which that
equation describes. In particular, the product-variable approach to modeling an
interaction effect involving two independent variables does not imply that the interaction
is “symmetrical” or that each independent variable causes change in the other’s impact on
the dependent variable.
Of course, for some purposes we do not need to go any further than describing the
regression surface. When we need to include an interaction effect only in order to have a
correctly specified analytic equation, for example, our inability to go beyond describing
the regression surface is not a substantive hindrance. For other purposes, however,
knowledge about underlying causal mechanisms is crucial and errors can have serious
consequences. Believing that a Type I mechanism is present when in reality a Type III
mechanism is operating, for example, could lead to an ineffective policy recommendation
that has no effect. Specifically, if the mechanism shown in Figure 4 is present, increasing
the value of Z will have no effect on Y’s value when X is absent (has a value of zero).
Believing that the mechanism shown in Figure 2 is operational in this case might lead to
one to recommend a policy change aimed at increasing Z’s value, because a Type I
interaction effect specifies that Z affects Y even in the absence of X. Thus, even though

22
we cannot distinguish between different possible causal mechanisms solely on the basis
of the empirical results of studies employing product variables, different causal
mechanisms can produce substantially different outcomes.
Finally, considering the causal mechanisms that can underlie an interaction effect
reveals a limitation of the usual statistical test for the presence of an interaction effect,
which involves assessing the statistical significance of the coefficient for the product
variable. Specifically, if a Type I interaction is present and α1 and γ1 in equation 8 have
similar magnitudes but opposite signs, the value of βxz in equation 1 will be near zero,
and presumably not statistically significant, leading to the erroneous conclusion that no
interaction effect is present. Researchers unwilling to specify that at least one of the
independent variables has no effect on the others’ causal impact must therefore be
confident that α1 and γ1 have the same sign before they can treat the usual statistical test
as being a general test for the presence of an interaction effect. Obviously, when
researchers want to carry out a simultaneous test for several possible interactions, such as
all of the possible two way interactions between gender and a group of other independent
variables, they need to have information about the causal mechanisms underlying each of
the interactions before they can be confident that they are carrying out a general test of
interaction effects.
In practice, we usually lack theoretical knowledge about the causal mechanisms
that underlie interaction effects. This unfortunate state of affairs limits what we can learn
from estimating interaction effect models to questions that can be answered in terms of
interaction-effect regression surfaces. Recognition of this limitation will not only prevent
researchers from erroneously interpreting regression surfaces as giving information about

23
the causal mechanisms underlying interaction effects, but also encourage researchers to
develop more adequate theoretical specifications of the interaction effects in which they
are interested.

24
Notes
1. This paper draws on insights contained in two important papers. The first, Allison (1977), has been
heavily cited. The second, Fisher (1988) is rarely cited, and papers that cite it do so for points tangential to
its main message, which is that preexisting knowledge or theory is required before one can understand the
meaning of an interaction effect. I leave it to the reader to judge how much farther I have been able to see
by standing on the shoulders of these two giants.

2. This usage of the word “interaction” is recognized by almost no dictionaries and appears to be due to R.
A. Fisher, who adopted a term meaning “deviations from additivity” from genetics (Box 1978, p. 111;
Fisher 1924, p. 200).

3. Although my discussion here focuses on the case where the independent variables involved in an
interaction are both quantitative variables, the conclusions I draw below hold equally for cases where either
or both of the independent variables is categorical.

4. Here we are specifying that, for example, when Z equals zero, changes in X’s value produce changes in
Y. This is equivalent to specifying that βx in equation 1 is non-zero.

5. Level-1 equations have a dependent variable, Y, on their left-hand sides and level-2 equations have a
coefficient, β, on their left-hand sides. In the multilevel-analysis literature level-2 equations have
additional properties. For example, in that literature variables in level-2 equations characterize nested
groupings of observations, and level-2 equations typically include disturbance terms. This paper does not
assume any of these additional properties.

6. One could also view this as a subtype of a Type I interaction specifying that either

α1

or

γ1

equals

zero. Because it is so prominent, however, I distinguish this kind of interaction from the case where both

25

α1

and

γ1

have non-zero values. This follows the convention of treating causal models with the same

variables but different causal effects as different models (Blalock 1962).

7. Multilevel models usually specify that level-2 equations have disturbance terms. An alternative in this
case might be to specify equation 4 as the level-1 equation and equation 11 as a single level-2 equation.
Regardless of one’s choice, ordinary least-squares gives incorrect estimates of coefficients’ standard errors
and researchers should therefore use other estimation procedures (Mason et al., 1983). This estimation
problem does not affect the interpretational issue that I address in this paper, however.

8. In this case one would need to have sufficient cases for each observed value of X, and reasonable
variation in Z for each value of X, to reliably estimate the impact of X on Z’s effect on Y.

9. Here I follow the typology of scales proposed by Stevens (1951). Interval scales have quantitative
categories with equal intervals between successive integer values, but lack an absolute zero point.
10. The main exception to this generalization are “gravity” or “intervening opportunity” models of
migration, which hold that migration between two geographical areas is the product of their population
sizes and the distance between them, and which use ratio-scale measures of these concepts. See, for
example Stewart (1948).

26
Bibliography

Aiken, Leona S. and Stephen G. West. (1991) Multiple Regression: Testing and
Interpreting Interactions. Newbury Park, CA: Sage.
Allison, Paul D. (1977) “Testing for Interaction in Multiple Regression.” American
Journal of Sociology 83: 144-153.
Allison, Paul D. (1999) Multiple Regression: A Primer. Thousand Oaks, CA: Pine
Forge Press.
Bollen, Kenneth A. (1989) Structural Equations with Latent Variables. New York:
John Wiley and Sons.
Box, Joan F. (1978) R. A. Fisher: The Life of a Scientist. New York: John Wiley and
Sons.
Braumoeller, Bear F. (2004) “Hypothesis Testing and Multiplicative Interaction Terms.”
International Organization 58: 807-820.
Blalock, Hubert M., Jr. (1962) “Four-Variable Causal Models and Partial Correlations.”
American Journal of Sociology 68: 182-194.
Blalock, Hubert M., Jr. (1965) “Theory Building and the Concept of Interaction.”
American Sociological Review 30: 374-381.
Bobko, Philip. (1986) “A Solution to Some Dilemmas When Testing Hypotheses about
Ordinal Interactions.” Journal of Applied Psychology 71: 323-326.
Cohen, Jacob, Patricia Cohen, Steven G. West and Leona S. Aiken. (2003) Applied
Multiple Regression/Correlation Analysis for the Behavioral Sciences. Mahwah,
NJ: Lawrence Erlbaum Associates.
Corno, Lyn, Lee J. Cronbach, Haggai Kupermintz, David F Lohman, Ellen B Mandinach,
Ann W. Porteus, Joan E. Talbert. (2002) Remaking the Concept of Aptitude:
Extending the Legacy of Richard E. Snow. Mahwah, NJ: Lawrence Erlbaum
Associates.
Cronbach, Lee J. (1987) “Statistical Tests for Moderator Variables: Flaws in Analyses
Recently Reported.” Psychological Bulletin 102: 414-417.
Fisher, Gene A. (1988) “Problems in the Use and Interpretation of Product Variables.”
Pp. 84-107 in J. Scott Long (Ed.) Common Problems/Proper Solutions: Avoiding
Error in Quantitative Research. Newbury Park, CA: Sage.

27
Fisher, Ronald A. (1924) “The Biometrical Study of Heredity.” Eugenics Review
16:189-210.
Fox, John. (1997) Applied Regression Analysis, Linear Models, and Related Methods.
Thousand Oaks, CA: Sage.
Hox, Joop. (2002) Multilevel Analysis: Techniques and Applications. Mahwah, NJ:
Lawrence Erlbaum Associates.
Kozlowski, Steve W. J. and Katherine J. Klein. (2000) “A Multilevel Approach to
Theory and Research in Organizations: Contextual, Temporal and Emergent
Processes.” Pp. 3 – 90 in Katherine J. Klein and Steve W. J. Kozlowski (Eds.)
Multilevel Theory, Research, and Methods in Organizations. San Francisco:
Jossey-Bass.
Manski, Charles F. (1993) “Identification Problems in the Social Sciences.” Pp. 1-56 in
Peter V. Marsden (Ed.) Sociological Methodology 1993. Oxford: Basil
Blackwell.
Marini, Margaret M and Burton Singer. (1988) “Causality and Degrees of
Determination in Social Sciences.” Pp. 347-409 in Clifford C. Clogg (Ed.)
Sociological Methodology 1988. Washington, D.C.: American Sociological
Association.
Marsden, Peter V. (1981) “Conditional Effects in Regression Models.” Pp. 97-116 in P.
V. Marsden (Ed.) Linear Models in Social Research. Newbury Park, CA: Sage.
Mason, William M., George Y. Wong and Barbara Entwistle. (1983) “Contextual
Analysis through the Multilevel Linear Model.” Pp. 72 – 103 in Samuel
Linehardt (Ed.) Sociological Methodology 1983-1984. San Francisco: JosseyBass.
McClendon, McKee J. (1994) Multiple Regression and Causal Analysis. Itaska, IL: F.
E. Peacock.
Saunders, David R. (1956) “Moderator Variables in Prediction.” Educational and
Psychological Measurement 16: 209-222.
Smith, Herbert L. (1990) “Specification Problems in Experimental and
Nonexperimental Social Research.” Pp. 59-91 in Clifford C. Clogg (Ed.)
Sociological Methodology 1990. Oxford: Basil Blackwell.
Southwood, Kenneth E. (1978) “Substantive Theory and Statistical Interaction: Five
Models. American Journal of Sociology 83: 1154-1203.

28
Stevens, S. S. (1951) “Mathematics, Measurement and Psychophysics.” Pp. 1-49 in S.
S. Stevens (Ed.). Handbook of Experimental Psychology. New York: Wiley.
Stewart, John Q. (1948) “Demographic Gravitiation: Evidence and Applications.”
Sociometry 11: 31-58.
Stolzenberg, Ross M. (1974) “Estimating an Equation with Multiplicative and Additive
Terms, with an Application to Analysis of Wage Differentials between Men and
Women in 1960.” Sociological Methods and Research 2: 313-331.
Stolzenberg, Ross M. (1979) “The Measurement and Decomposition of Causal Effects
in Nonlinear and Nonadditive Models.” Pp. 459 – 488 in Karl F. Schuessler (Ed.)
Sociological Methodology 1980. San Francisco, CA: Jossey-Bass.
Zeisel, Hans. (1968) Say it with Figures (Fifth Edition). New York: Harper and Row.

29

Y

Slope = βx
Slope = βz

β0

X
X=b

Slope = βz + b βxz
Z
Z=a

Slope = βx + a βxz

Figure 1. A Warped Regression Surface with β0 > 0, β1> 0, β2> 0, and β3< 0.

30

X

Y

Z

Figure 2. A Type I Interaction Effect

X

Y

Z

Figure 3. A Type II Interaction Effect

31

X

Y

Z

Figure 4. A Type III Interaction Effect

X*Y

Figure 5. A Type IV Interaction Effect

Y

